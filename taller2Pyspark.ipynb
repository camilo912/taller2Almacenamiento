{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{ \"conf\":{\n",
    "\"spark.pyspark.python\": \"python3\",\n",
    "\"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "\"spark.pyspark.virtualenv.type\":\"native\",\n",
    "\"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078d6ec6213d4a87a6c59ed655532184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[nltk_data] Downloading package punkt to /var/lib/livy/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip."
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a1d3cc5de74d29b3838d34962e7e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1572892671684_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-31-97.ec2.internal:20888/proxy/application_1572892671684_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-26-200.ec2.internal:8042/node/containerlogs/container_1572892671684_0003_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.6/site-packages (from pandas) (1.14.5)\n",
      "Collecting python-dateutil>=2.6.1\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas) (2019.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-0.25.3 python-dateutil-2.8.1\n",
      "\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from nltk) (1.12.0)\n",
      "\n",
      "Collecting tqdm\n",
      "  Using cached https://files.pythonhosted.org/packages/05/f2/764a5d530cf143ded9bc95216edb6e258c6554511e78de7c250557e8f3ed/tqdm-4.37.0-py2.py3-none-any.whl\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.37.0\n",
      "\n",
      "Collecting Ipython\n",
      "  Using cached https://files.pythonhosted.org/packages/81/2e/59cdacea6476a4c21b7c090a91250ffbcd085900f5eb9f4e4d68dd2ee4e3/ipython-7.9.0-py3-none-any.whl\n",
      "Collecting prompt-toolkit<2.1.0,>=2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/87/61/2dfea88583d5454e3a64f9308a686071d58d59a55db638268a6413e1eb6d/prompt_toolkit-2.0.10-py3-none-any.whl\n",
      "Collecting traitlets>=4.2\n",
      "  Using cached https://files.pythonhosted.org/packages/ca/ab/872a23e29cec3cf2594af7e857f18b687ad21039c1f9b922fac5b9b142d5/traitlets-4.3.3-py2.py3-none-any.whl\n",
      "Processing /var/lib/livy/.cache/pip/wheels/98/b0/dd/29e28ff615af3dda4c67cab719dd51357597eabff926976b45/backcall-0.1.0-cp36-none-any.whl\n",
      "Collecting pygments\n",
      "  Using cached https://files.pythonhosted.org/packages/5c/73/1dfa428150e3ccb0fa3e68db406e5be48698f2a979ccbcec795f28f44048/Pygments-2.4.2-py2.py3-none-any.whl\n",
      "Collecting pickleshare\n",
      "  Using cached https://files.pythonhosted.org/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl\n",
      "Collecting pexpect; sys_platform != \"win32\"\n",
      "  Using cached https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl\n",
      "Collecting decorator\n",
      "  Using cached https://files.pythonhosted.org/packages/8f/b7/f329cfdc75f3d28d12c65980e4469e2fa373f1953f5df6e370e84ea2e875/decorator-4.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=18.5 in /mnt/tmp/1572922811309-0/lib/python3.6/site-packages (from Ipython) (41.6.0)\n",
      "Collecting jedi>=0.10\n",
      "  Using cached https://files.pythonhosted.org/packages/55/54/da994f359e4e7da4776a200e76dbc85ba5fc319eefc22e33d55296d95a1d/jedi-0.15.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->Ipython) (1.12.0)\n",
      "Collecting wcwidth\n",
      "  Using cached https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl\n",
      "Collecting ipython-genutils\n",
      "  Using cached https://files.pythonhosted.org/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl\n",
      "Collecting ptyprocess>=0.5\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/29/605c2cc68a9992d18dada28206eeada56ea4bd07a239669da41674648b6f/ptyprocess-0.6.0-py2.py3-none-any.whl\n",
      "Collecting parso>=0.5.0\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/bd/bf4e5bd01d79906e5b945a7af033154da49fd2b0d5b5c705a21330323305/parso-0.5.1-py2.py3-none-any.whl\n",
      "Installing collected packages: wcwidth, prompt-toolkit, decorator, ipython-genutils, traitlets, backcall, pygments, pickleshare, ptyprocess, pexpect, parso, jedi, Ipython\n",
      "Successfully installed Ipython-7.9.0 backcall-0.1.0 decorator-4.4.1 ipython-genutils-0.2.0 jedi-0.15.1 parso-0.5.1 pexpect-4.7.0 pickleshare-0.7.5 prompt-toolkit-2.0.10 ptyprocess-0.6.0 pygments-2.4.2 traitlets-4.3.3 wcwidth-0.1.7\n",
      "\n",
      "Processing /var/lib/livy/.cache/pip/wheels/e1/41/5e/e201f95d90fc84f93aa629b6638adacda680fe63aac47174ab/tabulate-0.8.5-cp36-none-any.whl\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.5\n",
      "\n",
      "Collecting boto3\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/a4/75004e7352a9f3565331e6881a2312a79e46e434c24e5146b0e6c97fa08f/boto3-1.10.9-py2.py3-none-any.whl (128kB)\n",
      "Collecting botocore<1.14.0,>=1.13.9\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/45/042a6db7d025be8b04bd47528bc8db414de02e2e5802142e9fb45610d620/botocore-1.13.9-py2.py3-none-any.whl (5.3MB)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0\n",
      "  Using cached https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3) (0.9.4)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Using cached https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl\n",
      "Collecting python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"\n",
      "  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "Collecting urllib3<1.26,>=1.20; python_version >= \"3.4\"\n",
      "  Using cached https://files.pythonhosted.org/packages/e0/da/55f51ea951e1b7c63a579c09dd7db825bb730ec1fe9c0180fc77bfb31448/urllib3-1.25.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.9->boto3) (1.12.0)\n",
      "Installing collected packages: docutils, python-dateutil, urllib3, botocore, s3transfer, boto3\n",
      "  Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "Successfully installed boto3-1.10.9 botocore-1.13.9 docutils-0.15.2 python-dateutil-2.8.0 s3transfer-0.2.1 urllib3-1.25.6\n",
      "\n",
      "Collecting scipy\n",
      "  Using cached https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.6/site-packages (from scipy) (1.14.5)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.3.1"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package('pandas')\n",
    "sc.install_pypi_package('nltk')\n",
    "sc.install_pypi_package('tqdm')\n",
    "sc.install_pypi_package('Ipython')\n",
    "sc.install_pypi_package('tabulate')\n",
    "sc.install_pypi_package('boto3')\n",
    "sc.install_pypi_package('scipy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bae951081c422c970da4d18d483645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os, csv, glob, json, uuid, pickle, math\n",
    "import nltk\n",
    "import numpy as np, scipy, pandas as pd\n",
    "from operator import itemgetter\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "from tqdm import tqdm\n",
    "from pyspark.ml.feature import Word2Vec, Word2VecModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se añaden las credenciales, y se crean las funciones de lectura y almacenado en s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1fea9af3164f1a98297203853ee88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "myaws_access_key_id='ASIARN3W6NVX7FRG4TUN'\n",
    "myaws_secret_access_key='J1e1Yaqv32/NvtbABv6yZ9l4CrOTshushsiAn6Hn'\n",
    "myaws_session_token='FwoGZXIvYXdzEEwaDDpTc667NepABYlmviLEAd5YcUzTXU+8IXMuWodjQ43QwAqskTjy9z1gKGEcZkNq3Fc7h13IMwEs/0/b3gEw6/mamJufuDM8LHm9s8KjyDQUBMzi7haz2dECJ41O10xXjkUv69B4/z2tmJUiJiy68+xAMCFSOY0Sopg0pjezecpe5c7JdexMXgpfwc7OXCBtAqj+PszNIpGE9llt/7h+NmBv7C5tkHYeRqVLZ6ONf1z7JEvE1WYO1m73UHlUpA5dqE9Md11JAsNt2/YAmXzrOSZHDFko28GD7gUyLXZ5AVTMiUyRjaQs+MtF9cIPmLv9J2Gi7mlsrJ1XO30dTotTFDPBEYsI3M6I3g=='\n",
    "mybucket_name = 'taller2'\n",
    "\n",
    "s3client = boto3.client('s3',\n",
    "    aws_access_key_id=myaws_access_key_id,\n",
    "    aws_secret_access_key=myaws_secret_access_key,\n",
    "    aws_session_token=myaws_session_token\n",
    ")\n",
    "\n",
    "s3resource = boto3.resource('s3',\n",
    "    aws_access_key_id=myaws_access_key_id,\n",
    "    aws_secret_access_key=myaws_secret_access_key,\n",
    "    aws_session_token=myaws_session_token\n",
    ")\n",
    "\n",
    "def test_s3object(prefix):\n",
    "    mybucket = s3resource.Bucket(mybucket_name) # just Bucket name\n",
    "    obj = list(mybucket.objects.filter(Prefix=prefix))\n",
    "    if len(obj) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def list_s3dir(prefix, q=''):\n",
    "    keys = []\n",
    "    kwargs = {'Bucket': mybucket_name, 'Prefix': prefix}\n",
    "    resp = s3client.list_objects_v2(**kwargs)\n",
    "    for obj in resp['Contents']:\n",
    "        if(q in obj['Key']):\n",
    "            keys.append(obj['Key'])\n",
    "    return keys\n",
    "    \n",
    "def create_s3folder(folder_name):\n",
    "    s3client.put_object(Bucket=mybucket_name, Key=(folder_name+'/'))\n",
    " \n",
    "def write_s3file(fname,fcontent):\n",
    "    file = s3resource.Object(mybucket_name,fname)\n",
    "    file.put(Body=fcontent)\n",
    "\n",
    "    \n",
    "def upload_s3file(file_name, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param file_name: File to upload\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    try:\n",
    "        response = s3client.upload_file(file_name, mybucket_name, object_name)\n",
    "    except s3client.exceptions.ObjectNotInActiveTierError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def read_s3file(fname):\n",
    "    data = s3client.get_object(Bucket=mybucket_name, Key=fname)\n",
    "    return data['Body']\n",
    "\n",
    "def download_s3file(s3fname, fname):\n",
    "    s3client.download_file(mybucket_name, s3fname, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean la estructura de carpetas en s3 para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3398a09ccba44c11acb43981aa6bf5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CONTENT_INDEX = 8\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "CONTENT_PATH = 'taller2/inputs/contents/'\n",
    "TOKENS_PATH = 'taller2/inputs/tokens/'\n",
    "CENTROIDS_PATH = 'taller2/inputs/centroids/'\n",
    "BM25_PATH = 'taller2/inputs/bm25/'\n",
    "MODEL_PATH = 'taller2/model/'\n",
    "\n",
    "\n",
    "if not test_s3object(CONTENT_PATH):\n",
    "    create_s3folder(CONTENT_PATH)\n",
    "    \n",
    "if not test_s3object(TOKENS_PATH):\n",
    "    create_s3folder(TOKENS_PATH)\n",
    "    \n",
    "if not test_s3object(CENTROIDS_PATH):\n",
    "    create_s3folder(CENTROIDS_PATH)\n",
    "\n",
    "if not test_s3object(BM25_PATH):\n",
    "    create_s3folder(BM25_PATH)\n",
    "\n",
    "if not test_s3object(MODEL_PATH):\n",
    "    create_s3folder(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee los csv, y se almacena en txt el contenido, y a este se tokeniza por sentencias, luego se almacena en s3 tanto los txt como las sentencias de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5dfbae87964b1f9544310ee4afe7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "df = spark.read.csv('s3://' + mybucket_name + '/taller2/inputs/*.csv', header=True)\n",
    "for line in df.rdd.collect():\n",
    "    count = count + 1\n",
    "    content = line['content']\n",
    "    cname = CONTENT_PATH + str(count) + '.txt'\n",
    "    tname = TOKENS_PATH + str(count) + '.tokens'\n",
    "    write_s3file(cname,content)\n",
    "\n",
    "    sentences = \"\"\n",
    "    for sentence in nltk.sent_tokenize(content):\n",
    "        sentences = sentences + sentence.lower() + \"\\n\"\n",
    "\n",
    "    write_s3file(tname, sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen las sentencias de tokens almacenados, y se tokeniza ahora por palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062891ceb8044a34a8adaded937b2853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = []\n",
    "for line in sc.textFile('s3://' + mybucket_name + '/taller2/inputs/tokens/*.tokens').collect():\n",
    "    sentences.append(nltk.word_tokenize(line.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el modelo de work2Vec de pyspark ml, se entrena y por ultimo mostramos sus vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbeb62eee2894dd3a976670719e1a831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|        word|              vector|\n",
      "+------------+--------------------+\n",
      "|     rahmani|[0.02666660957038...|\n",
      "|   professed|[-0.0367599017918...|\n",
      "|    incident|[-0.1251610517501...|\n",
      "|     serious|[0.05088722705841...|\n",
      "|       brink|[-0.0597794316709...|\n",
      "|     acronym|[-0.1773192435503...|\n",
      "|    youthful|[-0.0930401235818...|\n",
      "|      comply|[-0.0892204791307...|\n",
      "|      breaks|[0.03824375942349...|\n",
      "|   forgotten|[0.14248335361480...|\n",
      "|    precious|[-0.0242347232997...|\n",
      "|inflammatory|[-0.1000339612364...|\n",
      "|     sectors|[-0.0100088017061...|\n",
      "|   ascension|[-0.0473112575709...|\n",
      "|      teresa|[-0.0028897654265...|\n",
      "|      hourly|[-0.0276485644280...|\n",
      "|    embedded|[-0.1272780597209...|\n",
      "|     derided|[0.04470048099756...|\n",
      "|       lover|[-0.0176430493593...|\n",
      "|     speaker|[0.23745933175086...|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "inputs = [(x,) for x in sentences]\n",
    "doc = spark.createDataFrame(inputs, [\"sentence\"])\n",
    "word2Vec = Word2Vec(vectorSize=5, seed=42, inputCol=\"sentence\", outputCol=\"model\")\n",
    "model = word2Vec.fit(doc)\n",
    "model.getVectors().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarda el modelo en S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9ed3851f0240e98c95929e5d99d907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save('s3://'+ mybucket_name +'/taller2/model/word2vec-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee el modelo desde s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ebc83608a24ff28555d543bb3b872c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = None\n",
    "model = Word2VecModel.load('s3://'+ mybucket_name +'/taller2/model/word2vec-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se almacena en s3 el vocabulario generado en el modelo en un json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee843c61c0f42968a144ba321342323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = model.getVectors().select('word').collect()\n",
    "vocab = dict([(v.word, k) for k, v in enumerate(words)])\n",
    "write_s3file('taller2/model/w2v-lc-vocab.json', json.dumps(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbc387bc6e04be4ad86271d15d007d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     word|similarity|\n",
      "+---------+----------+\n",
      "|    texas|   1.00000|\n",
      "|     adm.|   0.99168|\n",
      "| kwakiutl|   0.98910|\n",
      "|  wyoming|   0.98877|\n",
      "|   senate|   0.98821|\n",
      "|breitbart|   0.98749|\n",
      "|    zarif|   0.98700|\n",
      "|     mick|   0.98431|\n",
      "|     1973|   0.98276|\n",
      "|  officer|   0.98211|\n",
      "+---------+----------+"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number as fmt\n",
    "\n",
    "# texas - senate + alabama = congress\n",
    "vectors = model.getVectors()\n",
    "t = vectors.filter(vectors.word == 'texas').select('vector').collect()[0]['vector']\n",
    "# como senate y alabama no están en el dataset de prueba se simulan con ceros\n",
    "s = np.array([0.0,0.0,0.0,0.0,0.0])\n",
    "a = np.array([0.0,0.0,0.0,0.0,0.0])\n",
    "r = t+s-a\n",
    "# r = a-t+s\n",
    "model.findSynonyms(r, 10).select(\"word\", fmt(\"similarity\", 5).alias(\"similarity\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen los contenidos almacenados en s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a79828bffa47f6960dd9ee530bf449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               value|            filename|\n",
      "+--------------------+--------------------+\n",
      "|Joachim Neander w...|s3://taller2/tall...|\n",
      "|WASHINGTON  —   W...|s3://taller2/tall...|\n",
      "|When Indira Islas...|s3://taller2/tall...|\n",
      "|On the morning of...|s3://taller2/tall...|\n",
      "|In the fall of 20...|s3://taller2/tall...|\n",
      "|Hours before the ...|s3://taller2/tall...|\n",
      "|President Obama d...|s3://taller2/tall...|\n",
      "|One night six yea...|s3://taller2/tall...|\n",
      "|After the bullet ...|s3://taller2/tall...|\n",
      "|The Season 7 “Rea...|s3://taller2/tall...|\n",
      "|On the night of N...|s3://taller2/tall...|\n",
      "|WASHINGTON  —   O...|s3://taller2/tall...|\n",
      "|Canada, our No. 1...|s3://taller2/tall...|\n",
      "|A   of   lead exp...|s3://taller2/tall...|\n",
      "|Updated: 11:50 p....|s3://taller2/tall...|\n",
      "|• Hundreds of tho...|s3://taller2/tall...|\n",
      "|Thousands of year...|s3://taller2/tall...|\n",
      "|GLEN ELDER, Kan. ...|s3://taller2/tall...|\n",
      "|Danny Cahill stoo...|s3://taller2/tall...|\n",
      "|They called him t...|s3://taller2/tall...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from  pyspark.sql.functions import input_file_name\n",
    "df = spark.read.text('s3://'+ mybucket_name +'/taller2/inputs/contents/*.txt')\n",
    "df = df.withColumn(\"filename\", input_file_name())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula los centroides para cada uno de los contenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f69a37f0fb4c2491e741987a9daf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed:  882.6689670085907"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "dic = {k:v for k,v in vectors.collect()}\n",
    "for fname in df.rdd.collect():\n",
    "    rdd = sc.parallelize([fname['value']])\n",
    "    centroid_in = list(rdd.map(lambda x: [dic[w] if w in dic.keys() else [0.0,0.0,0.0,0.0,0.0] for w in x.lower().split(' ')]).map(lambda x: np.mean(x, axis=0)).collect()[0])\n",
    "    out_dict = { fname['filename'] : centroid_in}\n",
    "    json_file = 'taller2/inputs/centroids/' + os.path.basename(fname['filename'].split('/')[-1]).replace('.txt', '.json')\n",
    "    write_s3file(json_file, json.dumps(out_dict))\n",
    "print('time elapsed: ', time.time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el diccionario de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89bf9e5324f46a9af6affdd98091663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sents = [(s,) for s in sentences]\n",
    "df = spark.createDataFrame(sents)\n",
    "dictionary = df.rdd.map(lambda x: x[0]).reduce(lambda x,y: list(np.unique(list(x)+list(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los centroides almacenados en s3, y se leen en un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a3be482c934d3cb9993e27286ee6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "centroid_dict = {}\n",
    "dfCentroide = spark.read.text('s3://'+ mybucket_name +'/taller2/inputs/centroids/*.json')\n",
    "for fname in dfCentroide.rdd.collect():\n",
    "    d = json.loads(fname['value'])\n",
    "    centroid_dict.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676ec03ff7884551a3ea7bed940c15fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_centroid_dict = {k: centroid_dict[k] for k in centroid_dict if not np.isnan(centroid_dict[k][0]).any()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf027778ebc46cc90a30ed2394b9048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_embedding(x, out=False):\n",
    "    if x in dictionary:\n",
    "        return vectors.filter(vectors.word == x).select('vector').collect()[0]['vector']\n",
    "    else:\n",
    "        return np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffb6f49d9e34b379f5e60a207c23287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_document(q_embeddings, d_centroid):\n",
    "    individual_csims = [(1 - scipy.spatial.distance.cosine(qin, d_centroid)) for qin in q_embeddings]\n",
    "    return (sum(individual_csims)/len(q_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1821ea0a56448e6bba3c8c2691006d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = []\n",
    "df = spark.read.text('s3://'+ mybucket_name +'/taller2/inputs/contents/*.txt')\n",
    "for fname in df.rdd.collect():\n",
    "    documents.append(nltk.word_tokenize(fname['value'].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e1abcecbfe4be8ad0a5c3d247b90ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num words in query:  5 Num query word in vectors:  5"
     ]
    }
   ],
   "source": [
    "query = 'texas buys border with mexico'\n",
    "query_words = nltk.word_tokenize(query.lower())\n",
    "query_ins = [get_embedding(x) for x in query_words]\n",
    "q_len = len(query_ins)\n",
    "print('Num words in query: ', len(query_words), 'Num query word in vectors: ', q_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095d2333cc524d6d9d5bd3744a6fcfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_in_in = []\n",
    "for k,v in clean_centroid_dict.items():\n",
    "    scores_in_in.append((k, score_document(query_ins, v[0])))\n",
    "\n",
    "scores_in_in = sorted(scores_in_in, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc65beb1d9a44f3bd9d4d12ecf8ddac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 5 IN-IN:\n",
      "s3://taller2/taller2/inputs/contents/523.txt\n",
      "s3://taller2/taller2/inputs/contents/631.txt\n",
      "s3://taller2/taller2/inputs/contents/497.txt\n",
      "s3://taller2/taller2/inputs/contents/104.txt\n",
      "s3://taller2/taller2/inputs/contents/147.txt"
     ]
    }
   ],
   "source": [
    "print('TOP 5 IN-IN:')\n",
    "top_5_in_in = [x[0] for x in scores_in_in[:5]]\n",
    "\n",
    "for fname in top_5_in_in:\n",
    "    print(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
